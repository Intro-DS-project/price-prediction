{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "a = torch.randn(8, 64)\n",
    "b = torch.randn(8, 64)\n",
    "\n",
    "torch.cat((a, b), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \n",
    "key ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from supabase import create_client, Client\n",
    "from datetime import date\n",
    "import datetime\n",
    "\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = supabase.table('entries').select(\"*\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import location\n",
    "\n",
    "print(len(location.get_all_streets()))\n",
    "print(len(location.get_all_wards()))\n",
    "print(len(location.get_all_districts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location.standardize_district_name(\"Hà Nội\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_street(street):\n",
    "    street = location.standardize_street_name(street)\n",
    "    if street not in location.get_all_streets():\n",
    "        return -1\n",
    "    street_encoded = location.get_all_streets().index(street)\n",
    "    \n",
    "    return street_encoded\n",
    "\n",
    "def encode_ward(ward):\n",
    "    ward = location.standardize_ward_name(ward)\n",
    "    if ward not in location.get_all_wards():\n",
    "        return -1\n",
    "    ward_encoded = location.get_all_wards().index(ward)\n",
    "    \n",
    "    return ward_encoded\n",
    "\n",
    "def encode_district(district):\n",
    "    district = location.standardize_district_name(district)\n",
    "    if district not in location.get_all_districts():\n",
    "        return -1\n",
    "    district_encoded = location.get_all_districts().index(district)\n",
    "    \n",
    "    return district_encoded\n",
    "\n",
    "encode_street(\"Đại La\")\n",
    "encode_ward(\"Trương Định\")\n",
    "encode_district(\"Hai Ba Trung\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location.get_district_from_ward(\"Trương Định\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "for data in response.data:\n",
    "    if encode_street(data[\"street\"]) == -1:\n",
    "        continue\n",
    "    if encode_ward(data[\"ward\"]) == -1:\n",
    "        continue\n",
    "    if encode_district(data[\"district\"]) == -1:\n",
    "        data[\"district\"] = location.get_district_from_ward(data[\"ward\"])\n",
    "        if data[\"district\"]:\n",
    "            print(data[\"district\"])\n",
    "            datas.append(data)\n",
    "            continue\n",
    "    datas.append(data)\n",
    "\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datas), len(response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data = train_test_split(datas, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "list_area = [int(data[\"area\"]) for data in train_data]\n",
    "\n",
    "area_mean = np.mean(list_area)\n",
    "area_std = np.std(list_area)\n",
    "\n",
    "area_mean, area_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RentDataset(Dataset):\n",
    "    def __init__(self, supabase_response, area_mean=None, area_std=None):\n",
    "       self.data = supabase_response\n",
    "       self.area_mean = area_mean\n",
    "       self.area_std = area_std\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        price = torch.Tensor([self.data[idx][\"price\"]])\n",
    "        if self.area_mean:\n",
    "            area = (self.data[idx][\"area\"] - self.area_mean) / self.area_std\n",
    "        else:\n",
    "            area = self.data[idx][\"area\"]\n",
    "        \n",
    "        street = encode_street(self.data[idx][\"street\"])\n",
    "        ward = encode_ward(self.data[idx][\"ward\"])\n",
    "        district = encode_district(self.data[idx][\"district\"])\n",
    "        \n",
    "        num_bedroom = self.data[idx][\"num_bedroom\"]\n",
    "        num_diningroom = self.data[idx][\"num_diningroom\"]\n",
    "        num_kitchen = self.data[idx][\"num_kitchen\"]\n",
    "        num_toilet = self.data[idx][\"num_toilet\"]\n",
    "        \n",
    "        attr = torch.Tensor([area, num_bedroom, num_diningroom, num_kitchen, num_toilet])\n",
    "        \n",
    "        return attr, street, ward, district, price\n",
    "\n",
    "train_dataset = RentDataset(train_data, area_mean=area_mean, area_std=area_std)\n",
    "valid_dataset = RentDataset(valid_data, area_mean=area_mean, area_std=area_std)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=len(valid_dataset), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_street = nn.Embedding(1572, 128)   # 1572 streets\n",
    "        self.embedding_ward = nn.Embedding(430, 128)   # 430 wards\n",
    "        self.embedding_district = nn.Embedding(25, 128)   # 25 districts\n",
    "        \n",
    "        self.linear_attr = nn.Linear(5, 128)\n",
    "        \n",
    "        self.linear2 = nn.Linear(512, 729)\n",
    "        self.linear3 = nn.Linear(729, 81)\n",
    "        self.linear4 = nn.Linear(81, 1)\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, attr, street, ward, district):\n",
    "        street_embeded = self.embedding_street(street)\n",
    "        ward_embeded = self.embedding_ward(ward)\n",
    "        district_embeded = self.embedding_district(district)\n",
    "        attr_embeded = self.linear_attr(attr)\n",
    "        \n",
    "        x = torch.cat((street_embeded, ward_embeded, district_embeded, attr_embeded), 1)\n",
    "        x = self.dropout(self.act(self.linear2(x)))\n",
    "        x = self.act(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super(RMSELoss,self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y) + self.eps)\n",
    "        return loss\n",
    "\n",
    "model = RentModel().to(device)\n",
    "# loss_fn = nn.MSELoss()\n",
    "loss_fn = RMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "print_per_batch = 1\n",
    "\n",
    "epoch_count, train_loss_values, valid_loss_values = [], [], []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (attr, street, ward, district, price) in enumerate(train_dataloader):\n",
    "        logits = model(attr, street, ward, district)\n",
    "        loss = loss_fn(logits, price)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % print_per_batch == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch:03d}/{num_epochs:03d}\"\n",
    "                f\" | Batch {batch_idx:03d}/{len(train_dataloader):03d}\"\n",
    "                f\" | Train Loss: {loss}\"\n",
    "            )\n",
    "        \n",
    "        train_loss_values.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch_idx, (attr, street, ward, district, price) in enumerate(valid_dataloader):\n",
    "            logits = model(attr, street, ward, district)\n",
    "            loss = loss_fn(logits, price)\n",
    "            print(\n",
    "                    f\"Epoch: {epoch:03d}/{num_epochs:03d}\"\n",
    "                    f\" | Batch {batch_idx:03d}/{len(valid_dataloader):03d}\"\n",
    "                    f\" | Val Loss: {loss}\"\n",
    "                )\n",
    "            \n",
    "            valid_loss_values.append(loss.item())\n",
    "            \n",
    "        if len(valid_loss_values) >= 3:\n",
    "            if valid_loss_values[-1] >= valid_loss_values[-2] and valid_loss_values[-2] >= valid_loss_values[-3]:\n",
    "                print(\"Maybe Overfitting... Stop!\")\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_values)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(valid_loss_values)\n",
    "plt.ylabel('Val Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            \"embedding_dims\": 128,\n",
    "            \"out_feature2\": 729,\n",
    "            \"out_feature3\": 81,\n",
    "            \"activation\": \"relu\",\n",
    "        }\n",
    "\n",
    "torch.save({'model_state_dict': model.state_dict(), 'config': config, \"loss\": valid_loss_values[-1]}, \"checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(8, 5)\n",
    "b = nn.Linear(5, 128)\n",
    "\n",
    "b(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/dinhhuy/ray_results/model_tuning_2024-05-10_12-30-39/model_tuning_6fa3c_00000_0_activation=relu,embedding_dims=32,lr=0.0000,out_feature2=729,out_feature3=64_2024-05-10_12-30-39/checkpoint_000000/checkpoint.pt\"\n",
    "\n",
    "checkpoint = torch.load(path)\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"ckpt_path.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"ckpt_path\": \"model/checkpoint.pt\"}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
